{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e4aedf",
   "metadata": {},
   "source": [
    "## 3. Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4582729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 14:16:53.724953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-02 14:16:53.893290: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-02 14:16:54.487632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexrichard/miniconda3/lib/\n",
      "2023-01-02 14:16:54.487721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexrichard/miniconda3/lib/\n",
      "2023-01-02 14:16:54.487730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from cv2 import resize\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from os import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import sleep\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(f\"{os.getcwd()}/working ViT/\")\n",
    "sys.path.append(f\"{os.getcwd()}/mltfm/\")\n",
    "from VisionTransformer_working import VisionTransformer as vit_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867e3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67aa2851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becfa61d",
   "metadata": {},
   "source": [
    "### MC Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe54e7b",
   "metadata": {},
   "source": [
    "Load CNN and ViT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a700261",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = vit_old(dspl_size=104, \n",
    "              patch_size=8, \n",
    "              embed_dim=128,\n",
    "              depth=12,\n",
    "              n_heads=8,\n",
    "              mlp_ratio=4.,\n",
    "              p=0.,\n",
    "              attn_p=0.,\n",
    "              drop_path=0.).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08eee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pth = 'working ViT/logs_and_weights/ViT-2022-Dec-10 23:18:41/ViT-2022-Dec-10 23:18:41_best_val_loss_2.365828e-06.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98d1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vit.load_state_dict(torch.load(path_to_pth)['best_model_weights'], strict=True)\n",
    "else:\n",
    "    vit.load_state_dict(torch.load(path_to_pth, map_location=torch.device('cpu'))['best_model_weights'], strict=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0947edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e1cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 14:17:23.016281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.021269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.021667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.022577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-02 14:17:23.024049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.024397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.024749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.567767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.568050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.568282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-02 14:17:23.568464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2023-01-02 14:17:23.586813: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 14.88M (15597568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.587143: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 13.39M (14038016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.587447: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 12.05M (12634368 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.587755: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 10.84M (11371008 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.588069: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 9.76M (10234112 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.588382: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 8.78M (9210880 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.588705: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 7.91M (8289792 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.589029: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 7.12M (7460864 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.589354: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 6.40M (6714880 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.589680: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 5.76M (6043392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.590009: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 5.19M (5439232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.590343: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 4.67M (4895488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.590671: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 4.20M (4406016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.591029: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.78M (3965440 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.591387: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.40M (3568896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.591744: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.06M (3212032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.592101: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.76M (2891008 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.592458: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.48M (2601984 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.592817: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.23M (2341888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.593182: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.01M (2107904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.593847: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 1.81M (1897216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.594511: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 1.63M (1707520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.595176: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 1.46M (1536768 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.595835: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 1.32M (1383168 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.596497: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 1.19M (1244928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.597158: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 1.07M (1120512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.597819: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 985.0K (1008640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.598483: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 886.5K (907776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.599137: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 798.0K (817152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.599798: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 718.2K (735488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.600454: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 646.5K (662016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.601118: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 582.0K (595968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.601780: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 524.0K (536576 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.602457: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 471.8K (483072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.603122: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 424.8K (434944 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.603787: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 382.5K (391680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.604450: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 344.2K (352512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.605114: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 310.0K (317440 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.605775: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 279.0K (285696 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.606445: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 251.2K (257280 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.607110: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 226.2K (231680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.607775: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 203.8K (208640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.608439: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 183.5K (187904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.609104: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 165.2K (169216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.609769: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 148.8K (152320 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.610444: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 134.0K (137216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.611110: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 120.8K (123648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.611775: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 108.8K (111360 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.612439: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 98.0K (100352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.613103: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 88.2K (90368 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.613767: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 79.5K (81408 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.614432: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 71.8K (73472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.615099: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 64.8K (66304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.615760: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 58.5K (59904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.616426: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 52.8K (54016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.617091: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 47.5K (48640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.617756: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 42.8K (43776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.618423: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 38.5K (39424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.619088: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 34.8K (35584 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.619753: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 31.5K (32256 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.620415: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 28.5K (29184 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.621076: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 25.8K (26368 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.621742: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 23.2K (23808 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.622416: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 21.0K (21504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.623082: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 19.0K (19456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.623745: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 17.2K (17664 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.624409: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 15.8K (16128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.625074: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 14.2K (14592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.625732: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 13.0K (13312 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.626401: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 11.8K (12032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.627066: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 10.8K (11008 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.627729: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 9.8K (9984 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.628394: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 9.0K (9216 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.629058: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 8.2K (8448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.629719: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 7.5K (7680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.630395: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 6.8K (6912 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.631057: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 6.2K (6400 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.631721: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 5.8K (5888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.632384: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 5.2K (5376 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.633048: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 4.8K (4864 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.633711: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 4.5K (4608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.634376: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 4.2K (4352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.635040: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 4.0K (4096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.635702: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.8K (3840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.636361: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.5K (3584 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.637024: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.2K (3328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.637685: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 3.0K (3072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.638352: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.8K (2816 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.639017: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.5K (2560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.639679: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.640342: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.641001: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.641665: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.642339: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.643000: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.643658: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.644326: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.644985: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.645647: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.646307: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.646972: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.647635: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.648298: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.648961: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.649624: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.650297: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.650962: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.651624: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.652287: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.652950: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.653612: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.654277: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.654941: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.655603: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.656261: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.656925: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.657587: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.658253: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.658917: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.659658: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.660322: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.660992: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.661652: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.662318: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.662983: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.663648: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.664312: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.664975: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.665638: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.666300: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.666966: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.667628: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.668291: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.668953: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.669615: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.670295: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.670960: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.671619: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.672283: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.672945: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.673608: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.674273: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.674938: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.675602: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.676325: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.676996: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.677658: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.678324: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.678990: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.679653: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.680316: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.680979: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.681638: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.682312: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.682977: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.683639: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.684303: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.684965: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.685627: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.686295: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.686956: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.687621: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.688284: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.688944: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.689618: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.690292: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.690960: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.691614: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.692245: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.693007: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.693671: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.694340: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.695000: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.695660: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.696320: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.696978: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.697645: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.698311: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.698974: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.699638: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.700301: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.700971: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.701634: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.702309: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.702976: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.703640: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.704305: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.704969: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.705665: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.706340: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.707044: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.707722: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.708391: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.709054: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.709728: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.710402: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.711067: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.711727: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.712390: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.713051: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.713713: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.714378: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.715044: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.715710: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.716372: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.717031: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.717698: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.718365: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.719029: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.719691: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.720353: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.721022: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.721684: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.722353: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.723021: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.723680: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.724349: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.725014: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.725676: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.726420: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.727081: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.727745: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.728412: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.729076: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.729739: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.730410: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.731073: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.731737: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.732395: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.733059: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.733722: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.734393: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.735058: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.735723: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.736388: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.737049: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.737715: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.738381: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.739042: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.739706: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.740373: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.741036: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.741737: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.742404: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.743074: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.743738: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.744402: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.745067: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.745733: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.746407: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.747073: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.747735: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.748473: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.749145: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.749809: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.750479: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.751151: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.751848: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.752515: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.753181: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.753841: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.754512: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.755175: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.755839: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.756510: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.757175: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.757836: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.758507: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.759174: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.759838: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.760501: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.761165: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.761829: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.762492: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.763158: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.763823: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.764488: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.765152: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.765815: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.766487: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.767155: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.767816: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.768481: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.769146: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.769811: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.770477: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.771149: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.771813: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.772476: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.773141: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.773805: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.774470: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.775136: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.775800: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.776465: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.777130: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.777790: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.778467: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.779133: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.779797: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.780462: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.781127: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.781790: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.782456: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 14:17:23.783117: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.783784: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.784445: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.785110: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.785774: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.786450: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.787117: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.787777: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.788443: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.789107: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.789771: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.790437: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.791102: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.791766: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.792431: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.793094: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.793758: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.794423: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.795090: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.795754: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.796419: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.797084: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.797748: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.798419: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.799088: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.799748: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.800407: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.801076: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.801740: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.802406: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.803066: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.803733: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.804396: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.805060: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.805723: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.806397: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.807063: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.807729: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.808389: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.809060: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.809767: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.810435: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.811098: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.811762: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.812425: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.813083: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.813748: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.814413: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.815077: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-02 14:17:23.815738: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = keras.models.load_model('../mltfm/models/model_noise_1e-4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c45ed",
   "metadata": {},
   "source": [
    "Enable dropout during inference in the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7861ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cnn_weights.get_config()\n",
    "\n",
    "for i, layer in enumerate(config['layers']):\n",
    "    if layer['class_name'] == 'Dropout':\n",
    "        layer['inbound_nodes'][0][0][-1]['training'] = True\n",
    "        \n",
    "cnn_ = keras.Model.from_config(config)\n",
    "cnn_.load_weights('mltfm/models/model_noise_1e-4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98896ead",
   "metadata": {},
   "source": [
    "For both the CNN and ViT, compute `n_forward_passes` for each of the 25 test samples. Note that the CNN contains 6 dropout layers (p=0.1) and the ViT contains 12 dropout layers in the MLP module of each encoder block (p=0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d794925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_dist import inference_with_dropout\n",
    "\n",
    "n_forward_passes = 10\n",
    "\n",
    "predictions_vit = torch.zeros(25, 10, 2, 104, 104)\n",
    "predictions_cnn = torch.zeros(25, 10, 2, 104, 104)\n",
    "for i in range(0, len(X_test)):\n",
    "    for j in range(0, n_forward_passes):\n",
    "        predictions_vit[i, j, :, :, :] = inference_with_dropout(vit_weights, X_test[i][np.newaxis, ...], return_attn_scores=False)\n",
    "        predictions_cnn[i, j, :, :, :] = torch.tensor(np.moveaxis(np.array((cnn_(dspl[i][np.newaxis, ...]))), 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460cd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate loss per prediction and loss of averaged prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_pred_vit = 1/n_forward_passes * predictions_vit.sum(dim=1)\n",
    "averaged_pred_cnn = 1/n_forward_passes * predictions_cnn.sum(dim=1)\n",
    "\n",
    "losses_vit = torch.zeros(25, 10)\n",
    "losses_cnn = torch.zeros(25, 10)\n",
    "for i in range(0, len(X_test)):\n",
    "    for j in range(0, n_forward_passes):\n",
    "        losses_vit[i, j] = torch.sum(loss(predictions_vit[i, j], Y_test[i]))\n",
    "        losses_cnn[i, j] = torch.sum(loss(predictions_cnn[i, j], Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mean_per_sample_vit = torch.mean(losses_vit, axis=1)\n",
    "loss_mean_per_sample_cnn = torch.mean(losses_cnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ade818",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_variance_per_sample_vit = torch.var(losses_vit, axis=1)\n",
    "loss_variance_per_sample_cnn = torch.var(losses_cnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_rmse_vit = torch.mean(loss_mean_per_sample_vit)\n",
    "avg_test_rmse_cnn = torch.mean(loss_mean_per_sample_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46503d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_rmse_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a70559",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_rmse_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe13dbe",
   "metadata": {},
   "source": [
    "Compute empirical variances for each predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_vit = np.var(predictions_vit.detach().numpy(), axis=1)\n",
    "variances_cnn = np.var(predictions_cnn.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37e12e",
   "metadata": {},
   "source": [
    "Plot predicted variances for one in-distribution test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(9, 8))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "\n",
    "im = axs[0, 0].imshow(variances_vit[0, 0, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[0, 0].set_title('test_sample_00: Variance of predictions in x-plane (ViT)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[0, 0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "im = axs[0, 1].imshow(variances_vit[0, 1, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[0, 1].set_title('test_sample_00: Variance of predictions in y-plane (ViT)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[0, 1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "im = axs[1, 0].imshow(variances_cnn[0, 0, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[1, 0].set_title('test_sample_00: Variance of predictions in x-plane (CNN)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[1, 0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "im = axs[1, 1].imshow(variances_cnn[0, 1, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[1, 1].set_title('test_sample_00: Variance of predictions in y-plane (CNN)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[1, 1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc879726",
   "metadata": {},
   "source": [
    "Corrupt test samples with Gaussian noise (i.e. create out-of-distribution samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382252da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1e-3\n",
    "cov = torch.tensor([[sigma**2,0],[0,sigma**2]])\n",
    "noise = np.random.multivariate_normal(np.array([0,0]),cov, (len(X_test),104,104))\n",
    "noisy_test = dspl + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl_noisy_ = np.moveaxis(np.array(noisy_test),3 ,1)\n",
    "X_test_noisy = torch.from_numpy(dspl_noisy_).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_predictions_vit = torch.zeros(1, 10, 2, 104, 104)\n",
    "noisy_predictions_cnn = torch.zeros(1, 10, 2, 104, 104)\n",
    "        \n",
    "noisy_predictions_vit[0, :, :, :, :] = inference_with_dropout(vit_weights, X_test_noisy[0][np.newaxis, ...], return_attn_scores=False)\n",
    "noisy_predictions_cnn[0, :, :, :, :] = torch.tensor(np.moveaxis(np.array((cnn_(noisy_test[0][np.newaxis, ...]))), 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ad34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_pred_vit = 1/n_forward_passes * noisy_predictions_vit.sum(dim=1)\n",
    "averaged_pred_cnn = 1/n_forward_passes * noisy_predictions_cnn.sum(dim=1)\n",
    "\n",
    "losses_noisy_vit = torch.zeros(1, 10)\n",
    "losses_noisy_cnn = torch.zeros(1, 10)\n",
    "for i in range(0, len(noisy_predictions_vit)):\n",
    "    for j in range(0, n_forward_passes):\n",
    "        losses_noisy_vit[i, j] = torch.sum(loss(noisy_predictions_vit[i, j], Y_test[i]))\n",
    "        losses_noisy_cnn[i, j] = torch.sum(loss(noisy_predictions_cnn[i, j], Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c07e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mean_per_noisy_sample_vit = torch.mean(losses_vit, axis=1)\n",
    "loss_mean_per_noisy_sample_cnn = torch.mean(losses_cnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_noisy_vit = np.var(noisy_predictions_vit.detach().numpy(), axis=1)\n",
    "variances_noisy_cnn = np.var(noisy_predictions_cnn.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29411aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_of_averaged_vit_pred = torch.sum(loss(averaged_pred_vit, Y_test[0]))\n",
    "loss_of_averaged_cnn_pred = torch.sum(loss(averaged_pred_cnn, Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c93b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(2,2, figsize=(9, 9))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "axs[0, 0].quiver(dspl[0,:,:,0], dspl[0,:,:,1], scale=1)\n",
    "axs[0, 0].set_title('Input (test_sample_00)', {'fontsize': 11})\n",
    "\n",
    "axs[0, 1].quiver(trac[0,:,:,0], trac[0,:,:,1], scale=10)\n",
    "axs[0, 1].set_title('Ground truth (test_sample_00)', {'fontsize': 11})\n",
    "\n",
    "axs[1, 0].quiver(averaged_pred_vit[0,0,:,:].detach().numpy(), averaged_pred_vit[0,1,:,:].detach().numpy(), scale=10)\n",
    "axs[1, 0].set_title(f'ViT prediction (loss: {loss_of_averaged_vit_pred})', {'fontsize': 11})\n",
    "\n",
    "axs[1, 1].quiver(averaged_pred_cnn[0,0,:,:], averaged_pred_cnn[0,1,:,:], scale=10)\n",
    "axs[1, 1].set_title(f'CNN prediction (loss: {loss_of_averaged_cnn_pred})', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e044448",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(9, 8))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "\n",
    "im = axs[0, 0].imshow(variances_noisy_vit[0, 0, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[0, 0].set_title('test_sample_00: Variance of predictions in x-plane (ViT)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[0, 0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "im = axs[0, 1].imshow(variances_noisy_vit[0, 1, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[0, 1].set_title('test_sample_00: Variance of predictions in y-plane (ViT)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[0, 1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "im = axs[1, 0].imshow(variances_noisy_cnn[0, 0, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[1, 0].set_title('test_sample_00: Variance of predictions in x-plane (CNN)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[1, 0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "im = axs[1, 1].imshow(variances_noisy_cnn[0, 1, :, :], cmap='jet', interpolation = 'nearest')\n",
    "axs[1, 1].set_title('test_sample_00: Variance of predictions in y-plane (CNN)', {'fontsize': 10})\n",
    "divider = make_axes_locatable(axs[1, 1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input an all-zero displacement field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weights.eval()\n",
    "all_zeros = torch.zeros(2,104,104).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vit = vit_weights(all_zeros[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93549c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.sum(loss(pred_vit[0], all_zeros))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(1,1, figsize=(6, 6))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "axs.quiver(pred_vit[0][0,:,:].detach().numpy(), pred_vit[0][1,:,:].detach().numpy(), scale=1)\n",
    "axs.set_title('Input (test_sample_00)', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7572def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mean = variances_vit[:,0,0,0].detach().numpy().mean()\n",
    "var = variances_vit[:,0,0,0].detach().numpy().var()\n",
    "gt = test_gt_00[0,0,0,0]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "textstr = '\\n'.join((\n",
    "    r'$\\mathrm{mean}=%.1e$' % (mean),\n",
    "    r'$\\mathrm{var}=%.1e$' % (var)))\n",
    "    \n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "ax.text(0.03, 0.97, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "counts, bins = np.histogram(stacked_predictions_vit[:,0,0,0].detach().numpy(), bins=50)\n",
    "max_counts = np.max(counts)\n",
    "ax.stairs(counts, bins)\n",
    "ax.hist(bins[:-1], bins, weights=counts, color='dodgerblue', ec='black')\n",
    "ax.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n",
    "ax.axvline(mean, color='black', linestyle='dashed', linewidth=1)\n",
    "ax.axvline(gt, color='mediumseagreen', linestyle='dashed', linewidth=1.5, label='ground truth')\n",
    "ax.text(mean*1.1, 0.85*max_counts, 'mean', rotation=90, fontsize=7)\n",
    "ax.text(gt*1.12, 0.85*max_counts, 'ground truth', rotation=90, fontsize=7)\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('Predicted values');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cc9b8",
   "metadata": {},
   "source": [
    "### Distance in latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095b20f",
   "metadata": {},
   "source": [
    "\"What the neural net is essentially doing is stripping away details from the features that are not helpful and amplifying the most important ones, and by the time we get to the latent space, it’s basically the way the model sees the molecule to make the prediction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl = h5py.File('data/displacements_25.h5')[\"data\"]\n",
    "trac = h5py.File('data/tractions_25.h5')[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl_ae = np.array(dspl[0:110, :, :, :])\n",
    "dspl_vit = np.moveaxis(np.array(dspl_ae),3 ,1)\n",
    "\n",
    "X_train_ae = torch.from_numpy(dspl_ae).double()\n",
    "X_test_vit = torch.from_numpy(dspl_vit).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c07c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentRepresentationExtractor(nn.Module):\n",
    "    def __init__(self, patch_embed, pos_embed, blocks):\n",
    "        super().__init__()\n",
    "        self.patch_embed = patch_embed\n",
    "        self.pos_embed = pos_embed\n",
    "        self.blocks = blocks\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = x + self.pos_embed  # (n_samples, n_patches, embed_dim)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x, _ = block(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320571",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_extractor = LatentRepresentationExtractor(vit_weights.patch_embed, vit_weights.pos_embed, vit_weights.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd132f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = representation_extractor(X_test_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = representations.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ee246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10 * 169 , 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 8)\n",
    "        )\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(8, 32),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(32, 64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 128),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 10 * 169),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 10 * 169)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = DeepAutoencoder().to(device).double()\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a703547",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = representations[0:100, :, :].double()\n",
    "X_val = representations[100:, :, :].double()\n",
    "\n",
    "train_set = TensorDataset(X_train, X_train)\n",
    "val_set = TensorDataset(X_val, X_val)\n",
    "\n",
    "dataloader_kwargs = {'batch_size': 10,\n",
    "                     'num_workers': 10,\n",
    "                     'pin_memory': False,\n",
    "                     'shuffle': True}\n",
    "dataloaders = {'train': DataLoader(train_set, **dataloader_kwargs),\n",
    "               'val': DataLoader(val_set, **dataloader_kwargs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loss_fn, dataloader, device, epoch, optimizer, train, visualize_attn=False):\n",
    "    # Set model to training mode\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        # Iterate over data\n",
    "        for xb, yb in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            yb = yb.reshape(-1, 10 * 169)\n",
    "\n",
    "            # zero the parameters\n",
    "            if train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # forward\n",
    "            if visualize_attn:\n",
    "                pred, attn_scores = model(xb)  # attn_scores: [attn_1, ..., attn_depth]\n",
    "            else:\n",
    "                pred = model(xb)\n",
    "            if not train and visualize_attn:\n",
    "                with torch.set_grad_enabled(not train):\n",
    "                    attn_mat = torch.stack(attn_scores) # attn_mat.shape==(depth, samples, n_heads, n_patches**0.5, n_patches**0.5)\n",
    "                    attn_mat = attn_mat.squeeze(1) # shape remains unchanged unless samples==1, then: (depth, n_heads, n_patches**0.5, n_patches**0.5)\n",
    "                    attn_mat = torch.mean(attn_mat, dim=1) # if samples==1: attn_mat.shape==(depth, n_patches**0.5,n_patches**0.5)\n",
    "\n",
    "            with torch.set_grad_enabled(train):\n",
    "                loss = loss_fn(pred, yb)\n",
    "\n",
    "                # backward + optimize if in training phase\n",
    "                if train:\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "        tepoch.set_postfix(loss=epoch_loss)\n",
    "        sleep(0.01)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846efd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_fn, dataloaders, optimizer, device, writer, NAME, max_epochs, patience):\n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = -1\n",
    "    best_model_weights = {}\n",
    "    optimizer_state_dict_in_best_epoch = {}\n",
    "    model.to(device)\n",
    "    example_input, example_value = next(iter(dataloaders['train']))\n",
    "    writer.add_graph(model, example_input.to(device))\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        train_loss = run_epoch(model, loss_fn, dataloaders['train'], device, epoch, optimizer, train=True)\n",
    "        val_loss = run_epoch(model, loss_fn, dataloaders['val'], device, epoch, optimizer=None, train=False)\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{max_epochs}, train_loss: {train_loss}\")\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('val_loss', val_loss, epoch)\n",
    "\n",
    "        # Save best weights\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            optimizer_state_dict_in_best_epoch = copy.deepcopy(optimizer.state_dict())\n",
    "\n",
    "        # Early stopping\n",
    "        print(\n",
    "            f\"best_val_loss: {np.round(best_val_loss, 6)}, \"\n",
    "            f\"epoch: {epoch}, best_epoch: {best_epoch}, \"\n",
    "            f\"current_patience: {patience - (epoch - best_epoch)}\")\n",
    "        if epoch - best_epoch >= patience:\n",
    "            break\n",
    "\n",
    "    torch.save({\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_model_weights': best_model_weights,\n",
    "        'optimizer_state_dict_in_best_epoch': optimizer_state_dict_in_best_epoch,\n",
    "        'best_val_loss': best_val_loss\n",
    "    },\n",
    "        f'logs_and_weights/{NAME}/{NAME}_best_val_loss_{np.round(best_val_loss, 6)}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305fe6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"AE-{:%Y-%b-%d %H:%M:%S}\".format(datetime.now())\n",
    "writer = SummaryWriter(log_dir=f'logs_and_weights/{NAME}')\n",
    "fit(model, criterion, dataloaders, optimizer, device, writer, NAME, 100, 20)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    from scipy.spatial import Delaunay\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point = dspl[111, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point = np.moveaxis(np.array(new_point[np.newaxis]),3 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point = torch.from_numpy(new_point).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b37221",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point_rep = representation_extractor(new_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e2fa5",
   "metadata": {},
   "source": [
    "### [Gaussian process layers](https://arxiv.org/pdf/2106.00638.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551daa00",
   "metadata": {},
   "source": [
    "__Goal__: Use variance of GP as distance measure between new input and already observed training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c5230",
   "metadata": {},
   "source": [
    "__Idea__: \n",
    "  1. Combination of Deep Neural Networks (DNNs) and Gaussian Processes (GPs)\n",
    "  2. Scalable Variational Gaussian Processes (SVGPs): Complexity of O(m³) with m as number of inducing points\n",
    "  3. Use the outputs of a neural network as the input to an uncertainty aware GP\n",
    "  4. Given a new input sample, the GP model provides a predictive distribution over (univariate!) target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18956650",
   "metadata": {},
   "source": [
    "__Algorithm__: \n",
    "  1. Train backbone (e.g. CNN, Transformer) on some problem\n",
    "  2. Generate inducing points by feeding images into the model and embed them\n",
    "  3. Use these embedding points as inducing points for SVGP\n",
    "  4. Maximize SVGP parameters (e.g. scaling parameter of RBF kernel) by maximizing ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd280b0",
   "metadata": {},
   "source": [
    "__Problem__: For every target variable, one SVGP has to be trained. Furthermore, SVGPs assume independence between the target variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
