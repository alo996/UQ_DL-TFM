{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384bc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from cv2 import resize\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from pandas.core.common import flatten\n",
    "from os import cpu_count\n",
    "from scipy.io import savemat, loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import sleep\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(f\"{os.getcwd()}/ViT architecture/working ViT\")\n",
    "sys.path.append(f\"{os.getcwd()}/scripts/\")\n",
    "from VisionTransformer_working import VisionTransformer as Vit_old\n",
    "\n",
    "sys.path.append(f\"{os.getcwd()}/ViT architecture/Architecture tryouts/DPT/\")\n",
    "from VisionTransformer_working_for_DPT import VisionTransformer2 as Vit_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105eb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f26571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5d8eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750'\n",
    "val_data_path = '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Validation data/resolution_104'\n",
    "test_data_path = '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Test data/resolution_104'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e0b1a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dspl_paths = [] #to store image paths in list\n",
    "train_trac_paths = [] #to store image paths in list\n",
    "\n",
    "for file in os.listdir(train_data_path):\n",
    "    if file.startswith('dspl'):\n",
    "        train_dspl_paths.append(train_data_path + '/' + file)\n",
    "    elif file.startswith('trac'):\n",
    "        train_trac_paths.append(train_data_path + '/' + file)\n",
    "    \n",
    "train_dspl_paths = list(train_dspl_paths)\n",
    "train_trac_paths = list(train_trac_paths)\n",
    "train_dspl_paths.sort()\n",
    "train_trac_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4dd6c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_21.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_22.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_23.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_24.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_25.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_26.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_27.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_28.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_29.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_30.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_31.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_32.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_33.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_34.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_35.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_36.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_37.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_38.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_39.h5',\n",
       " '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_40.h5']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dspl_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcbe951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tables import *\n",
    "h5file = h5py.File(\"/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/Training data/resolution_104/3750/dspl_21.h5\", mode=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9739469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file['data'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a521d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFMDataset(Dataset):\n",
    "    def __init__(self, dspl_path, trac_path):\n",
    "        self.dspl_path = dspl_path\n",
    "        self.trac_path = trac_path\n",
    "        self.dataset = None\n",
    "        with h5py.File(self.dspl_path, 'r') as file:\n",
    "            self.dataset_len = file['data'].shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset is None:\n",
    "            self.dspl_dataset = torch.moveaxis(h5py.File(self.dspl_path, 'r')[\"data\"], 3, 1).float()\n",
    "            self.trac_dataset = torch.moveaxis(h5py.File(self.trac_path, 'r')[\"data\"], 3, 1).float()\n",
    "            \n",
    "        return self.dspl_dataset[index], self.trac_dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5491c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e614f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3",
   "language": "python",
   "name": "venv_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
