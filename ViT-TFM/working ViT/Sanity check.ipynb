{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import VisionTransformer as vit\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from os import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import sleep\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "cudnn.benchmark = True\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dspl = h5py.File('displacements_25.h5')[\"data\"]\n",
    "trac = h5py.File('tractions_25.h5')[\"data\"]\n",
    "\n",
    "dspl = np.moveaxis(np.array(dspl),3 ,1)\n",
    "trac = np.moveaxis(np.array(trac),3 ,1)\n",
    "\n",
    "X_train = torch.from_numpy(dspl).double()\n",
    "Y_train = torch.from_numpy(trac).double()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "# val_set = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "if device == 'cpu':\n",
    "    num_workers = os.cpu_count()\n",
    "else:\n",
    "    num_workers = 4 * torch.cuda.device_count()\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# dataloaders['val'] = DataLoader(val_set, batch_size=10*batch_size, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vit_model = vit.VisionTransformer(dspl_size=104, patch_size=8, embed_dim=128, depth=12, n_heads=8, mlp_ratio=4.,p=0., attn_p=0.,drop_path=0).double()\n",
    "n_params = sum(p.numel() for p in vit_model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.AdamW(vit_model.parameters(), lr=0.001, weight_decay=0.0005)  # to use with ViTs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_epoch(model, loss_fn, dataloader, device, epoch, optimizer, train):\n",
    "    # Set model to training mode\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        # Iterate over data\n",
    "        for xb, yb in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            # zero the parameters\n",
    "            if train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # forward\n",
    "            with torch.set_grad_enabled(train):\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "\n",
    "                # backward + optimize if in training phase\n",
    "                if train:\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "        epoch_rmse = np.sqrt(2 * epoch_loss)\n",
    "        tepoch.set_postfix(loss=epoch_loss)\n",
    "        sleep(0.01)\n",
    "    return epoch_loss, epoch_rmse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit(model, loss_fn, dataloaders, optimizer, device, writer, NAME, max_epochs, patience):\n",
    "    best_train_rmse = np.inf\n",
    "    best_epoch = -1\n",
    "    best_model_weights = {}\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        train_loss, train_rmse = run_epoch(model, loss_fn, dataloaders['train'], device, epoch, optimizer, train=True)\n",
    "        # val_loss, val_rmse = run_epoch(model, loss_fn, dataloaders['val'], device, epoch, optimizer=None, train=False)\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{max_epochs}, train_loss: {train_loss:.3f}, train_rmse: {train_rmse:.3f}\")\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_rmse', train_rmse, epoch)\n",
    "        # writer.add_scalar('val_loss', val_loss, epoch)\n",
    "        # writer.add_scalar('val_rmse', val_rmse, epoch)\n",
    "\n",
    "        # Save best weights\n",
    "        if train_rmse < best_train_rmse:\n",
    "            best_epoch = epoch\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # Early stopping\n",
    "        print(\n",
    "            f\"best train_rmse: {best_train_rmse:.3f}, epoch: {epoch}, best_epoch: {best_epoch}, current_patience: {patience - (epoch - best_epoch)}\")\n",
    "        if epoch - best_epoch >= patience:\n",
    "            break\n",
    "\n",
    "    torch.save(best_model_weights, f'{NAME}_best_train_rmse_{np.round(best_train_rmse, 3)}.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NAME = \"ViT-{:%Y-%b-%d %H:%M:%S}\".format(datetime.now())\n",
    "writer = SummaryWriter(log_dir='{}'.format(NAME))\n",
    "vit_model.to(device)\n",
    "fit(vit_model, loss, dataloaders, optimizer, device, writer, NAME, 5, 5)\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vit_weights = vit.VisionTransformer(dspl_size=104, patch_size=8, embed_dim=128, depth=12, n_heads=8, mlp_ratio=4.,p=0., attn_p=0.,drop_path=0).double()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn_weights = keras.models.load_model('/Users/alex/PycharmProjects/UQ_DL-TFM/mltfm/models/model_noise_1e-4.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vit_weights.load_state_dict(torch.load('ViT-2022-Oct-31 15:23:07_best_train_rmse_inf.pth'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dspl = h5py.File('displacements_5.h5')[\"data\"]\n",
    "trac = h5py.File('tractions_5.h5')[\"data\"]\n",
    "\n",
    "dspl_ = np.moveaxis(np.array(dspl),3 ,1)\n",
    "trac_ = np.moveaxis(np.array(trac),3 ,1)\n",
    "\n",
    "X_test = torch.from_numpy(dspl_).double()\n",
    "Y_test = torch.from_numpy(trac_).double()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_vit = vit_weights(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_cnn = cnn_weights.predict(dspl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = torch.nn.MSELoss(reduction='mean')\n",
    "loss_vit = loss(pred_vit, Y_test)\n",
    "loss_cnn = loss(torch.tensor(np.moveaxis(pred_cnn, 3, 1)), Y_test)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(2,2, figsize=(9, 9))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "axs[0, 0].quiver(dspl[0,:,:,0], dspl[0,:,:,1], scale=1)\n",
    "axs[0, 0].set_title('displacement field', {'fontsize': 11})\n",
    "\n",
    "axs[0, 1].quiver(trac[0,:,:,0], trac[0,:,:,1], scale=10)\n",
    "axs[0, 1].set_title('traction ground truth', {'fontsize': 11})\n",
    "\n",
    "axs[1, 0].quiver(pred_vit[0,0,:,:].detach().numpy(), pred_vit[0,1,:,:].detach().numpy(), scale=10)\n",
    "axs[1, 0].set_title(f'vit prediction (loss: {torch.round(loss_vit/5, decimals=8)})', {'fontsize': 11})\n",
    "\n",
    "axs[1, 1].quiver(pred_cnn[0,:,:,0], pred_cnn[0,:,:,1], scale=10)\n",
    "axs[1, 1].set_title(f'cnn prediction (loss: {torch.round(loss_cnn/5, decimals=8)})', {'fontsize': 11})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
