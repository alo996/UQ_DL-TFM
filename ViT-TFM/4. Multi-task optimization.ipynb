{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec97cc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:23:22.291866: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 10:23:22.388700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-01 10:23:22.388719: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-01 10:23:22.801403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-01 10:23:22.801442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-01 10:23:22.801447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'VisionTransformer_working'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 32\u001B[0m\n\u001B[1;32m     30\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mgetcwd()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/working ViT/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     31\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mgetcwd()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/mltfm/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mVisionTransformer_working\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisionTransformer \u001B[38;5;28;01mas\u001B[39;00m vit_old\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'VisionTransformer_working'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from cv2 import resize\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from os import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import sleep\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(f\"{os.getcwd()}/working ViT/\")\n",
    "sys.path.append(f\"{os.getcwd()}/mltfm/\")\n",
    "from VisionTransformer_working import VisionTransformer as vit_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22538345",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f857f",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c88ea",
   "metadata": {},
   "source": [
    "Optimization for a linear combination of similar tasks often yields models that are more accurate, generalize better and require less training data. A possible multi-task objective for TFM could be\n",
    "<h3><center>$\\mathcal{L} = \\alpha_{1}$$\\cdot MSE + \\alpha_{2}$$\\cdot DTMA + \\alpha_{3}$$\\cdot DDA$</center></h3>\n",
    "where\n",
    "<h3><center>$\\boldsymbol\\alpha > 0, \\space\\space\\sum_{i=1}^{3} \\alpha_{i} = 1$</center></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0529dc5",
   "metadata": {},
   "source": [
    "Try model trained on multi-task objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_multi = vit_old(dspl_size=104,\n",
    "                  patch_size=8,\n",
    "                  embed_dim=128,\n",
    "                  depth=12,\n",
    "                  n_heads=8,\n",
    "                  mlp_ratio=4.,\n",
    "                  p=0.,\n",
    "                  attn_p=0.,\n",
    "                  drop_path=0.).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd8750",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_multi_pth = '/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/working ViT/logs_and_weights/ViT-2023-Jan-09 11:57:14/ViT-2023-Jan-09 11:57:14_best_val_loss_0.003215498429.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vit_multi.load_state_dict(torch.load(path_to_multi_pth)['best_model_weights'], strict=True)\n",
    "else:\n",
    "    vit_multi.load_state_dict(torch.load(path_to_multi_pth, map_location=torch.device('cpu'))['best_model_weights'], strict=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl = np.array(h5py.File(f'data/extended data/allDisplacements.h5')['dspl'])\n",
    "trac_separated = np.array(h5py.File(f'data/extended data/allTractions.h5')['trac'])\n",
    "\n",
    "dspl = np.moveaxis(np.concatenate([dspl[i] for i in range(dspl.shape[0])], axis=0), 3, 1)\n",
    "trac_separated = np.moveaxis(np.concatenate([trac_separated[i] for i in range(trac_separated.shape[0])], axis=0), 3, 1)\n",
    "\n",
    "dspl_train = dspl[0:100, :, :, :]\n",
    "dspl_val = dspl[100:110, :, :, :]\n",
    "trac_train = trac_separated[0:100, :, :, :]\n",
    "trac_val = trac_separated[100:110, :, :, :]\n",
    "\n",
    "X_train = torch.from_numpy(dspl_train).float()\n",
    "Y_train = torch.from_numpy(trac_train).float()\n",
    "X_val = torch.from_numpy(dspl_val).float()\n",
    "Y_val = torch.from_numpy(trac_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ce27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiTask import multi_task_loss, dtma, dda, append_predictions_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_multi.eval()\n",
    "loss = multi_task_loss\n",
    "pred_vit_multi = vit_multi(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8599f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_vit_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42901178",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9, 5))\n",
    "fig.tight_layout(pad=2, w_pad=2, h_pad=2)\n",
    "\n",
    "axs[0].quiver(pred_vit_multi[0, 0, :, :].detach().numpy(), pred_vit_multi[0, 1, :, :].detach().numpy(), scale=3)\n",
    "axs[0].set_title('appended_predictions', {'fontsize': 11})\n",
    "\n",
    "axs[1].quiver(Y_train[0, 0, :, :], Y_train[0, 1, :, :], scale=3)\n",
    "axs[1].set_title('appended_targets', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf62a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(50, 2, figsize=(10, 120))\n",
    "fig.tight_layout(pad=2, w_pad=2, h_pad=2)\n",
    "\n",
    "for i in range(50):\n",
    "    axs[i, 0].quiver(appended_predictions[0, i, 0, :, :].detach().numpy(), appended_predictions[0, i, 1, :, :].detach().numpy(), scale=1)\n",
    "    axs[i, 0].set_title('appended_predictions', {'fontsize': 11})\n",
    "\n",
    "    axs[i, 1].quiver(appended_targets[0, i, 0, :, :], appended_targets[0, i, 1, :, :], scale=1)\n",
    "    axs[i, 1].set_title('appended_targets', {'fontsize': 11})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2bc10a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(1,2, figsize=(8, 8))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "\n",
    "axs[0].quiver(X_test[0, 0, :, :], X_test[0, 1, :, :], scale=1)\n",
    "axs[0].set_title('PointForcemeshes[0]', {'fontsize': 11})\n",
    "\n",
    "trac_test = torch.sum(trac_separated_test, dim=1)\n",
    "\n",
    "axs[1].quiver(X_test[10, 0, :, :], X_test[10, 1, :, :], scale=1)\n",
    "axs[1].set_title('PointForcemeshes[1]', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weights = vit_old(dspl_size=104,\n",
    "                      patch_size=8,\n",
    "                      embed_dim=128,\n",
    "                      depth=12,\n",
    "                      n_heads=8,\n",
    "                      mlp_ratio=4.,\n",
    "                      p=0.,\n",
    "                      attn_p=0.,\n",
    "                      drop_path=0.).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pth = 'working ViT/logs_and_weights/ViT-2022-Dec-10 23:18:41/ViT-2022-Dec-10 23:18:41_best_val_loss_2.365828e-06.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9855284",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vit_weights.load_state_dict(torch.load(path_to_pth)['best_model_weights'], strict=False)\n",
    "else:\n",
    "    vit_weights.load_state_dict(torch.load(path_to_pth, map_location=torch.device('cpu'))['best_model_weights'], strict=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dca864",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fce716",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspl = h5py.File('data/extended data/displacements_1.h5')[\"data\"]\n",
    "trac_separated = h5py.File('data/extended data/sep_tractions_1.h5')[\"data\"]\n",
    "\n",
    "dspl_ = np.moveaxis(np.array(dspl[0:50, :, :, :]),3 ,1)\n",
    "trac_separated_ = np.moveaxis(np.array(trac_separated[0:50, :, :, :]), 4, 2)\n",
    "\n",
    "X_test = torch.from_numpy(dspl_).double().to(device)\n",
    "trac_separated_test = torch.from_numpy(trac_separated_).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(trac_separated_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54538d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weights.eval()\n",
    "pred_vit = vit_weights(X_test[:, :, :, :])\n",
    "# pred_cnn = cnn_weights.predict(dspl[0:50, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fc4ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(3,2, figsize=(8, 10))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "\n",
    "axs[0, 0].quiver(pleaase[0, :, :, 0], pleaase[0, :, :, 1], scale=5)\n",
    "axs[0, 0].set_title('trac_separated_test[0, 0]', {'fontsize': 11})\n",
    "\n",
    "plt.imshow(pleaase[0, :, :, 2], cmap='hot', interpolation='none')\n",
    "\n",
    "axs[0, 1].plt.imshow(pleaase[0, :, :, 2], cmap='hot', interpolation='nearest')\n",
    "axs[0, 1].set_title('appended_predictions[0, 0]', {'fontsize': 11})\n",
    "\n",
    "axs[1, 0].quiver(trac_separated_test[0, 10, 0, :, :].detach().numpy(), trac_separated_test[0, 10, 1, :, :].detach().numpy(), scale=10)\n",
    "axs[1, 0].set_title('trac_separated_test[0, 13, 0]', {'fontsize': 11})\n",
    "\n",
    "axs[1, 1].quiver(trac_separated_test[0, 15, 0, :, :].detach().numpy(), trac_separated_test[0, 15, 1, :, :].detach().numpy(), scale=10)\n",
    "axs[1, 1].set_title('trac_separated_test[0, 20, 0]', {'fontsize': 11})\n",
    "\n",
    "axs[2, 0].quiver(trac_separated_test[0, 20, 0, :, :].detach().numpy(), trac_separated_test[0, 20, 0, :, :].detach().numpy(), scale=23)\n",
    "axs[2, 0].set_title('Y_test[0, 49, 0]', {'fontsize': 11})\n",
    "\n",
    "axs[2, 1].quiver(pred_vit[0,0,:,:].detach().numpy(), pred_vit[0,1,:,:].detach().numpy(), scale=13)\n",
    "axs[2, 1].arrow(43, 18, Y_test[0, 0, 43, 18], 1,fc='red')\n",
    "axs[2, 1].set_title('pred_vit', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e729d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tryout = h5py.File('/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/data/extended data/try_displacements_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tryout['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d918b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtma_ex = dtma(appended_predictions, trac_separated_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bd78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtma_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b147dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trac_separated_test[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a83bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtma_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1edcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trac_separated_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f236ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5, 5))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "\n",
    "axs[0].quiver(pred_vit[0, 0, 35, 12].detach().numpy(), pred_vit[0, 1, 35, 12].detach().numpy(), scale=0.05)\n",
    "axs[0].set_title('pred_vit[0, 0, 0]', {'fontsize': 11})\n",
    "\n",
    "axs[1].quiver(Y_test[0, 0, 35, 12].detach().numpy(), Y_test[0, 0, 35, 12].detach().numpy(), scale=0.05)\n",
    "axs[1].set_title('trac_separated_test[0, 0, 0]', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dac345",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54726bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "event_acc = EventAccumulator('/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/working ViT/logs_and_weights/ViT-2023-Jan-09 11:57:14')\n",
    "event_acc.Reload()\n",
    "# Show all tags in the log file\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16547b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_acc.Scalars(tag='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5114a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=f'/home/alexrichard/PycharmProjects/UQ_DL-TFM/ViT-TFM/working ViT/logs_and_weights/ViT-2023-Jan-11 10:36:58')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dde20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
