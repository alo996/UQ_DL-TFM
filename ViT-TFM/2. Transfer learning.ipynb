{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd74785",
   "metadata": {},
   "source": [
    "## 2. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6286bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 13:56:48.351241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-02 13:56:48.522543: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-02 13:56:49.165918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexrichard/miniconda3/lib/\n",
      "2023-01-02 13:56:49.166005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexrichard/miniconda3/lib/\n",
      "2023-01-02 13:56:49.166014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from cv2 import resize\n",
    "from datetime import datetime\n",
    "from gc import collect\n",
    "from os import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import sleep\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(f\"{os.getcwd()}/working ViT/\")\n",
    "sys.path.append(f\"{os.getcwd()}/mltfm/\")\n",
    "from VisionTransformer_working import VisionTransformer as vit_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089c4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249127ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e468cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_vit import ViT\n",
    "from VisionTransformer import RecTracHead, Identity, PretrainedVit\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6260d4ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resized_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(resize(\u001b[43mX_train\u001b[49m[\u001b[38;5;241m0\u001b[39m], dsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m384\u001b[39m), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "resized_test_tensor = torch.tensor(resize(X_train[0], dsize=(384, 384), interpolation=cv2.INTER_LINEAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc410a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(1,1, figsize=(4, 4))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "axs.quiver(resized_test_tensor[:, :, 0].detach().numpy(), resized_test_tensor[:, :, 1].detach().numpy(), scale=3)\n",
    "axs.set_title('Input (test_sample_00)', {'fontsize': 11})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5fab8",
   "metadata": {},
   "source": [
    "Modify `model_pretrained` for downstream task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pretrained = 'logs_and_weights/ViT-2022-Nov-24 12:43:22/ViT-2022-Nov-24 12:43:22_best_val_loss_0.00021.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1935d87b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PretrainedVit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vit_pretrained \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedVit\u001b[49m(model_pretrained\u001b[38;5;241m=\u001b[39mViT(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB_16_imagenet1k\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m      2\u001b[0m vit_pretrained\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(path_pretrained)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_weights\u001b[39m\u001b[38;5;124m'\u001b[39m], strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PretrainedVit' is not defined"
     ]
    }
   ],
   "source": [
    "vit_pretrained = PretrainedVit(model_pretrained=ViT(name='B_16_imagenet1k', pretrained=True, in_channels=2, num_classes=10).float())\n",
    "vit_pretrained.load_state_dict(torch.load(path_pretrained)['best_model_weights'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20585ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pretrained_vit = vit_pretrained(X_test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_pretrained_vit = torch.sum(loss(pred_pretrained_vit, Y_test), (1, 2, 3))\n",
    "loss_pretrained_vit = torch.reshape(loss_pretrained_vit, (25, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_pretrained_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dca2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(2,2, figsize=(9, 9))\n",
    "fig.tight_layout(pad=3, w_pad=3, h_pad=3)\n",
    "axs[0, 0].quiver(dspl[0,:,:,0], dspl[0,:,:,1], scale=1)\n",
    "axs[0, 0].set_title('Input (test_sample_00)', {'fontsize': 11})\n",
    "\n",
    "axs[0, 1].quiver(trac[0,:,:,0], trac[0,:,:,1], scale=10)\n",
    "axs[0, 1].set_title('Ground truth (test_sample_00)', {'fontsize': 11})\n",
    "\n",
    "axs[1, 0].quiver(pred_pretrained_vit[0,0,:,:].detach().numpy(), pred_pretrained_vit[0,1,:,:].detach().numpy(), scale=1)\n",
    "axs[1, 0].set_title(f'Pretrained ViT prediction (loss: {torch.round(loss_pretrained_vit[0,0], decimals=3)})', {'fontsize': 11})\n",
    "\n",
    "axs[1, 1].quiver(pred_cnn[0,:,:,0], pred_cnn[0,:,:,1], scale=10)\n",
    "axs[1, 1].set_title(f'CNN prediction (loss: {torch.round(loss_cnn[0,0], decimals=3)})', {'fontsize': 11})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
